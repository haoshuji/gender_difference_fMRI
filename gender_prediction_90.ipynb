{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data into libsvm format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demo', '__version__', '__header__', '__globals__']\n"
     ]
    }
   ],
   "source": [
    "label_path = '../bev/'\n",
    "feature_path = '../5_MRI2atlas_AAL90_thr/'\n",
    "\n",
    "labels_mat = sio.loadmat(os.path.join(label_path,'demo.mat'))\n",
    "print labels_mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4006 Precentral_L-Precentral_R <type 'list'>\n"
     ]
    }
   ],
   "source": [
    "feature_name_file = '../aal_Conns.txt'\n",
    "feature_name_list = []\n",
    "with open(feature_name_file, 'r') as fin:\n",
    "    feature_name_list = fin.read().split(',')\n",
    "print len(feature_name_list), feature_name_list[0], type(feature_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_labels = [0,1]\n",
    "feature_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(441, 4)\n",
      "20071016_02\n",
      "(1, 1)\n",
      "0\n",
      "440 440\n",
      "0 [u'20071016_02']\n"
     ]
    }
   ],
   "source": [
    "print labels_mat['demo'].shape\n",
    "print str(labels_mat['demo'][2,0][0])\n",
    "print labels_mat['demo'][3,2].shape\n",
    "print labels_mat['demo'][2,2].size\n",
    "ids_tmp = labels_mat['demo'][1:,0]\n",
    "labels_tmp = labels_mat['demo'][1:,2]\n",
    "print ids_tmp.size, labels_tmp.size\n",
    "print labels_tmp[1].size, ids_tmp[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read person id and its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:418, Male:179, Female:239\n"
     ]
    }
   ],
   "source": [
    "labels_dict = {}\n",
    "num_positive = 0\n",
    "num_negative = 0\n",
    "for i in range(ids_tmp.size):\n",
    "    # label of this person is not provided\n",
    "    if labels_tmp[i].size == 0:\n",
    "        continue\n",
    "    label_tmp = 0 if int(labels_tmp[i]) == 2 else 1\n",
    "    if label_tmp == 0:\n",
    "        num_negative += 1\n",
    "    else:\n",
    "        num_positive += 1\n",
    "    labels_dict[str(ids_tmp[i][0])] = label_tmp\n",
    "print(\"Total:{}, Male:{}, Female:{}\".format(num_negative+num_positive, num_positive, num_negative))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20080908_04  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081113_14  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081128_11  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20080917_02  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081119_12  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081107_08  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081210_13  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081203_11  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081118_04  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081110_09  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081114_08  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081210_07  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081126_02  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20080613_05  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20080613_06  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "20081127_12  is not in  ../5_MRI2atlas_AAL90_thr/\n",
      "n:402, d:4005\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "for key in labels_dict:\n",
    "    if os.path.isfile(os.path.join(feature_path, key+'.mat')):\n",
    "        # Load feature mat file\n",
    "        key_mat = sio.loadmat(os.path.join(feature_path, key+'.mat'))\n",
    "        n,n = key_mat['Wauc'].shape\n",
    "        # indices for upper matrix items without the diagonal items         \n",
    "        upper_item_idx = np.triu_indices(n,1)\n",
    "#         features.append(np.triu(key_mat['Wauc']).flatten().tolist())\n",
    "        features.append(key_mat['Wauc'][upper_item_idx].tolist())\n",
    "        labels.append(labels_dict[key])\n",
    "    else:\n",
    "        print key, ' is not in ', feature_path\n",
    "print(\"n:{}, d:{}\".format(len(features), len(features[0])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_features(clf, top_k=10):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "#     feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        print clf.coef_\n",
    "        top_features_idx = np.argsort(clf.coef_[i])[-top_k:]\n",
    "        if feature_names == []:\n",
    "            print(\"{}:{}\".format(class_label, top_features_idx))\n",
    "        else:\n",
    "            print(\"%s: %s\" % (class_label,\n",
    "                  \" \".join(feature_names[j] for j in top_features_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors, 0.582137834037/0.0521829368399\n",
      "Linear SVM, 0.582103844351/0.00281046506521\n",
      "RBF SVM, 0.594511251758/0.0125627312552\n",
      "Gaussian Process, 0.582103844351/0.00281046506521\n",
      "Decision Tree, 0.599637834037/0.0215307116662\n",
      "Random Forest, 0.589478824816/0.024630787977"
     ]
    }
   ],
   "source": [
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    scores = cross_val_score(clf, features, labels, cv=5)\n",
    "#     if hasattr(clf, 'coef_'):\n",
    "    print(\"{}, {}/{}\".format(name, np.mean(scores), np.std(scores)))\n",
    "#     if name not in [\"Nearest Neighbors\",  \"Linear SVM\", \"RBF SVM\",\"Gaussian Process\", \"Neural Net\"]:\n",
    "#         print_top_features(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'feature max: ', np.max(features), ' min: ', np.min(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_important_features(features, clf, num_selected_features=50):\n",
    "    importances = adaboost_clf.feature_importances_\n",
    "    X = np.array(features)\n",
    "    std = np.std([tree.feature_importances_ for tree in adaboost_clf.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(0,num_selected_features):\n",
    "        print(\"%d. feature %s (%f)\" % (f + 1, feature_name_list[indices[f]], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(num_selected_features), importances[indices[:num_selected_features]],\n",
    "           color=\"r\", yerr=std[indices[:num_selected_features]], align=\"center\")\n",
    "    plt.xticks(range(num_selected_features), indices[:num_selected_features])\n",
    "    plt.xlim([-1, num_selected_features])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "adaboost_clf = AdaBoostClassifier()\n",
    "adaboost_clf.fit(features, labels)\n",
    "plot_important_features(features, adaboost_clf, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale the feature and evaluate the performance of each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer\n",
    "\n",
    "normalization_methods_name = ['StandardScaler', 'RobustScaler', 'Normalizer']\n",
    "normalization_methods = [StandardScaler, RobustScaler, Normalizer]\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    for norm_name, norm in zip(normalization_methods_name, normalization_methods):\n",
    "        scores = cross_val_score((make_pipeline(norm(), clf)), features, labels, cv=5)\n",
    "        print(\"{},{}, {}/{}\".format(name, norm_name, np.mean(scores), np.std(scores)))\n",
    "#     if name not in [\"Nearest Neighbors\"]:\n",
    "#         print_top_features(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled_adaboost_clf = make_pipeline(StandardScaler(), AdaBoostClassifier())\n",
    "scaled_adaboost_clf.fit(features, labels)\n",
    "plot_important_features(features, scaled_adaboost_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    scores = cross_val_score((make_pipeline(RobustScaler(), clf)), features, labels, cv=5)\n",
    "    print(\"{}, {}/{}\".format(name, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    scores = cross_val_score((make_pipeline(Normalizer(), clf)), features, labels, cv=5)\n",
    "    print(\"{}, {}/{}\".format(name, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
